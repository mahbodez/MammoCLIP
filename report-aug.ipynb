{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3ab10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from richtqdm import RichTqdm\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import time\n",
    "from functools import partial\n",
    "from rich import print\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e19770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_prompt(\n",
    "    template: str,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compile a prompt template with the given keyword arguments.\n",
    "\n",
    "    Args:\n",
    "        template (str): The prompt template string.\n",
    "        **kwargs: Keyword arguments to fill in the template.\n",
    "\n",
    "    Returns:\n",
    "        str: The compiled prompt.\n",
    "    \"\"\"\n",
    "    return template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_response(\n",
    "    respone: str,\n",
    "    enclosing: tuple = (\"<\", \">\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Decode a response string by removing enclosing characters.\n",
    "\n",
    "    Args:\n",
    "        respone (str): The response string to decode.\n",
    "        enclosing (tuple): A tuple of two characters that enclose the response.\n",
    "\n",
    "    Returns:\n",
    "        str: The decoded response.\n",
    "    \"\"\"\n",
    "    start, end = enclosing\n",
    "    try:\n",
    "        result = respone.split(start)[1].split(end)[0]\n",
    "    except Exception:\n",
    "        result = respone\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc04ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))\n",
    "def openai_get_response(\n",
    "    client: OpenAI,\n",
    "    model: str,\n",
    "    prompt: str,\n",
    "):\n",
    "    response = (\n",
    "        client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=(\n",
    "                [\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ]\n",
    "            ),\n",
    "            timeout=15,\n",
    "        )\n",
    "        .choices[0]\n",
    "        .message.content\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200784cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n",
    "def google_get_response(\n",
    "    client: genai.Client,\n",
    "    model: str,\n",
    "    prompt: str,\n",
    "    rpm: int = 20,\n",
    "    max_tokens: int = 512,\n",
    "):\n",
    "    time.sleep(60/rpm)\n",
    "    response = client.models.generate_content(\n",
    "        model=model,\n",
    "        contents=[prompt],\n",
    "        config=types.GenerateContentConfig(\n",
    "            max_output_tokens=max_tokens,\n",
    "            #http_options=types.HttpOptions(timeout=15),\n",
    "        ),\n",
    "    ).text\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a highly experienced radiologist specializing in breast imaging.\n",
    "Your task is to paraphrase the provided mammogram report text, strictly adhering to these instructions:\n",
    "Preserve all medical facts and clinical findings from the original text.\n",
    "Do NOT add or omit any medical details.\n",
    "Maintain the original diagnostic meaning, clarity, and specificity.\n",
    "Only alter the sentence structure, phrasing, or synonyms where medically equivalent and clearly appropriate.\n",
    "Ensure the paraphrase is phrased naturally and professionally, as expected in clinical mammography reports.\n",
    "Preserve key medical terminology (e.g., BI-RADS categories, anatomical terms, pathology findings), but you may substitute medically approved synonyms if and only if they fully maintain the original meaning.\n",
    "\n",
    "The mammogram report in <> is as follows:\n",
    "\n",
    "<{report}>\n",
    "\n",
    "Your paraphrased report should be enclosed in <>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7239af16",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"openai-mini\": \"gpt-4.1-mini-2025-04-14\",\n",
    "    \"openai\": \"gpt-4.1-2025-04-14\",\n",
    "    \"google\": \"models/gemini-2.0-flash\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb66588",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_reports(\n",
    "    ref_df: pd.DataFrame,\n",
    "    report_col: str,\n",
    "    aug_report_col: str,\n",
    "    number_to_augment: int,\n",
    "    provider: str,\n",
    "):\n",
    "    get_response: callable = None\n",
    "    if \"openai\" in provider:\n",
    "        client = OpenAI()\n",
    "        get_response = partial(\n",
    "            openai_get_response, client=client, model=models[provider]\n",
    "        )\n",
    "        print(f\"Using [green]{provider}[/green] model: [bold blue]{models[provider]}\")\n",
    "    elif \"google\" in provider:\n",
    "        client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "        get_response = partial(\n",
    "            google_get_response, client=client, model=models[provider]\n",
    "        )\n",
    "        print(f\"Using [green]{provider}[/green] model: [bold blue]{models[provider]}\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported provider: {provider}\")\n",
    "\n",
    "    df = ref_df.copy(deep=True)\n",
    "    # if the aug col is non-existent, create it\n",
    "    if aug_report_col not in df.columns:\n",
    "        df[aug_report_col] = None\n",
    "    # sample a subset of reports to augment\n",
    "    conditions = (\n",
    "        (df[report_col].notna())\n",
    "        & (df[aug_report_col].isna())\n",
    "        & (df[report_col].str.strip().ne(\"\"))\n",
    "        & (df[\"l_cc\"].notna())\n",
    "        & (df[\"r_cc\"].notna())\n",
    "        & (df[\"l_mlo\"].notna())\n",
    "        & (df[\"r_mlo\"].notna())\n",
    "    )\n",
    "    # ------ Check if there are any reports to augment ------\n",
    "    n = min(\n",
    "        number_to_augment,\n",
    "        df.loc[conditions].shape[0],\n",
    "    )\n",
    "    if n == 0:\n",
    "        print(\"[red]No reports to augment[/red]\")\n",
    "        return df, 0\n",
    "    elif n < number_to_augment:\n",
    "        print(f\"[yellow]Only {n} reports available for augmentation[/yellow]\")\n",
    "    # ------ Sample n reports to augment ------\n",
    "    print(f\"[blue]Augmenting {n} reports[/blue]\")\n",
    "    indices = (\n",
    "        df.loc[conditions]\n",
    "        .sample(n=n, random_state=42, replace=False)\n",
    "        .index\n",
    "    )\n",
    "    # ------ Augment the reports ------\n",
    "    for index in (\n",
    "        pbar := RichTqdm(\n",
    "            indices,\n",
    "            desc=\"Augmenting reports\",\n",
    "            unit=\"report\",\n",
    "            total=len(indices),\n",
    "            transient=True,\n",
    "        )\n",
    "    ):\n",
    "        pbar.set_description(f\"Augmenting report {index}\")\n",
    "\n",
    "        report = df.at[index, report_col]\n",
    "        prompt = compile_prompt(template, report=report)\n",
    "        try:\n",
    "            response = get_response(prompt=prompt)\n",
    "        except Exception as e:\n",
    "            print(f\"[red]Error[/red]: {str(e)[:50]}\")\n",
    "            continue\n",
    "        augmented_report = decode_response(response)\n",
    "\n",
    "        df.at[index, aug_report_col] = augmented_report\n",
    "    # ------ Return the augmented reports ------\n",
    "    print(\"[green]Augmentation complete![/green]\")\n",
    "    return df, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfeefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_fill(\n",
    "    ref_df: pd.DataFrame,\n",
    "    output_file: str,\n",
    "    report_col: str,\n",
    "    aug_report_col: str,\n",
    "    total_number_to_augment: int,\n",
    "    batch_size: int,\n",
    "    provider: str,\n",
    "):\n",
    "    assert total_number_to_augment % batch_size == 0, \"total_number_to_augment must be divisible by batch_size\"\n",
    "    df = ref_df.copy(deep=True)\n",
    "    for i in range(0, total_number_to_augment, batch_size):\n",
    "        print(f\"[blue]Augmenting reports {i} to {i + batch_size}[/blue]\")\n",
    "        df, n = augment_reports(\n",
    "            ref_df=df,\n",
    "            report_col=report_col,\n",
    "            aug_report_col=aug_report_col,\n",
    "            number_to_augment=batch_size,\n",
    "            provider=provider,\n",
    "        )\n",
    "        if n == 0:\n",
    "            print(\"[red]No more reports to augment[/red]\")\n",
    "            break\n",
    "        # save the augmented reports\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"[green]Saved augmented reports to {output_file}[/green]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4cce28",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_fill(\n",
    "    ref_df=pd.read_csv(\"./data/mammo-aug-oai-08-ggl-04.csv\"),\n",
    "    output_file=\"./data/mammo-aug-oai-08-ggl-05.csv\",\n",
    "    report_col=\"report\",\n",
    "    aug_report_col=\"aug_report\",\n",
    "    total_number_to_augment=1120,\n",
    "    batch_size=112,\n",
    "    provider=\"google\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
